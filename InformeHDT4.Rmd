---
title: "Informe Hoja de Trabajo 4"
author: "Marco Ramirez 19588, Alfredo Quezada 191002, Estuardo Hernandez 19202"
date: "14/3/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ModelMetrics)
library(ggplot2)
```

# Modelos de Regresión Lineal

### Elabore  un  modelo  de  regresión  lineal  utilizando  el  conjunto  de  entrenamiento  que  hizo para  predecir  los  precios  de  las  casas.  Explique los resultados  a los que llega. Muestre  el modelo gráficamente. El experimento debe ser reproducible por lo que debe fijar que los conjuntos de entrenamiento y prueba sean los mismos siempre que se ejecute el código.

```{r include= TRUE}


#Definimos el porcentaje de datos de prueba
porcentaje<-0.7
#Ya que lo que deseamos es que el experimento sea repetible asignamos una semilla
set.seed(123)

#Calculo de percentiles
data<-read.csv('train.csv')
percentil <- quantile(data$SalePrice)


#Percentiles
estado<-c('Estado')
data$Estado<-estado


#Economica=0
#Intermedia=1
#Cara=2
data <- within(data, Estado[SalePrice<=129975] <- 0)

data$Estado[(data$SalePrice>129975 & data$SalePrice<=163000)] <- 1
data$Estado[data$SalePrice>163000] <- 2


#Regresion
corte <- sample(nrow(data),nrow(data)*porcentaje)
#Creamos nuestros datos de prueba y entrenamiento
train<-data[corte,]
test<-data[-corte,]


#Regresion lineal
fitLMPW<-lm(SalePrice~ ., data = train[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd", "SalePrice","LotArea")])

predL<-predict(fitLMPW, newdata = test)


#Verificando la predicci?n
resultados<-data.frame(test$SalePrice,predL)
pregunta2<-head(resultados, n=5)
grafica1<-ggplot(data=train,mapping = aes(x=SalePrice,y=GrLivArea ))+
  geom_point(color='red',size=2)+
  geom_smooth(method = 'lm',se=TRUE,color='black')+
  labs(title = 'Precio de venta ~ Pies cuadrados de vivienda',x="Precio de venta",y='Pies cuadrados de venta')+
  theme_bw()+theme(plot.title = element_text(hjust = 0.5))
```


```{r }
pregunta2

```

En la tabla mostrada anteriormente, se observa que la predicción de los precios de las casas no se alejan mucho de los precios verdaderos, por lo que se concluye que las variables seleccionadas para realizar la predicción tiene correlación con el precio de la casa, y por consiguiente el modelo está bien.

```{r include= FALSE}
#Multicolinealidad y correlación de las variables del modelo
pairs(data$SalePrice ~ data$GrLivArea)
pairs(data$SalePrice ~ data$YearBuilt)
pairs(data$SalePrice ~ data$BsmtUnfSF)
pairs(data$SalePrice ~ data$TotalBsmtSF)
pairs(data$SalePrice ~ data$GarageArea)
pairs(data$SalePrice ~ data$YearRemodAdd)
pairs(data$SalePrice ~ data$LotArea)
```

### Analice el modelo. Determine si hay multicolinealidad en las variables, y cuáles son las que aportan al  modelo, por su  valor de  significación.  Haga  un análisis  de  correlación  de  las variables del modelo y especifique si el modelo se adapta bien a los datos. Explique si hay sobreajuste (overfitting) o no.

```{r }
pairs(data$SalePrice ~ data$GrLivArea)

```

Con este gráfico se puede decir que la variable GrLivArea es la mejor que se puede utilizar porque tiene una correlacion de **`r cor(data$SalePrice,data$GrLivArea)`** siendo muy cercana a 1.

```{r }
pairs(data$SalePrice ~ data$YearBuilt)

```

Ahora con la variable YearBuilt se ve que no hay mucha correlación (`r cor(data$SalePrice,data$YearBuilt)`), sin embargo aporta significativamente al modelo.

```{r }
pairs(data$SalePrice ~ data$BsmtUnfSF)

```

Respecto a la variable BsmtUnfSF, se observa que no posee una buena correlacion, teniendo una correlacion de `r cor(data$SalePrice,data$BsmtUnfSF)`.

```{r }
pairs(data$SalePrice ~ data$TotalBsmtSF)

```

La correlación de la variable TotalBsmtSF tiene una correlacion de `r cor(data$SalePrice,data$TotalBsmtSF)` siendo mejor que la anterior, ya que nuevamente esta muy cercana a 1. 

```{r }
pairs(data$SalePrice ~ data$GarageArea)

```

La variable GarageArea también es útil porque tiene una correlación `r cor(data$SalePrice,data$GarageArea)`

```{r }
pairs(data$SalePrice ~ data$YearRemodAdd)

```

Con respecto a la variable YearRemodAdd, la correlación es de `r cor(data$SalePrice, data$YearRemodAdd)`, indicando que puede llegar a ser util, ya que posee una correlacion mayor a 0.5.

```{r }
pairs(data$SalePrice ~ data$LotArea)

```

La variable LotArea tiene una correlación de `r cor(data$SalePrice , data$LotArea)` demostrando que esta no es una buena variable para la regresion lineal.\n


```{r }
ggplot(data=train,mapping = aes(x=SalePrice,y=GrLivArea ))+
  geom_point(color='red',size=2)+
  geom_smooth(method = 'lm',se=TRUE,color='black')+
  labs(title = 'Precio de venta ~ Pies cuadrados de vivienda',x="Precio de venta",y='Pies cuadrados de venta')+
  theme_bw()+theme(plot.title = element_text(hjust = 0.5))
```
\n 


\n \n 
\n
Como se observa en la grafica, mediante la variable con mayor correlacion, en este caso es la variable, GrLivArea. Logramos obtener el modelo lineal, el cual la linea es la que nos minizima el error medio cuadrado. Ademas, como se observa en la grafica, se observa que muchos datos no se encuentran sobre la linea, indicando que no existe overfitting, ya que para que ello exista, se tendria todos los puntos sobre la linea, lo cual como se observa no tenemos. 


### Determine la calidad del modelo realizando un análisis de los residuos.

Los residuales se calculan restando del valor de y ajustado del valor de y. 
Usando una ecuacion podemos predecir el precio de la venta de las casas para el conjunto de pruebas. 

```{r include=FALSE}
predL<-predict(fitLMPW, newdata = test)


```

```{r}
summary(predL)
summary(test$SalePrice)

```
\n Como se observa mediante el summary de ambas variables, tanto en la variable que predijo y la variable del testeo, se demuestra que obtuvimos una buena prediccion, ya que segun el resumen, tenemos varios datos similares, tal como se observa en el promedio.
Ahora veamos esto graficamente.

```{r}
plot(fitLMPW)

```

En la grafica **Residuals vs Fitte**, se muestra los residuos estandarizados contra el modelo lineal, y tal como se observa, no se posee algun patron de datos demostrando que son aleatorios. 

En la grafica **Normal Q-Q** logramos observar que los datos son normales, cabe mencionar que se posee algunos datos atipicos, sin embargo, la mayoria son normales. 

En la grafica **Scale-Location** vemos que los datos siguen siendo normales y cercanos a la linea, ademas de no observar algun patron. 

Y nuevamente en la grafica **Residuals vs Leverage**, no se presenta patron alguno.


```{r}
boxplot(fitLMPW$residuals)

```
\n 


\n
\n
Como se observa en la grafica , la caja no se encuentra centrada ademas de contar con muchos datos atipicos, por ello es necesario modificar el modelo. Eliminando varios datos atipicos.



```{r include=FALSE }
replace_outliers <- function(x, removeNA = TRUE){
  qrts <- quantile(x, probs = c(0.25, 0.75), na.rm = removeNA)
  caps <- quantile(x, probs = c(.05, .95), na.rm = removeNA)
  iqr <- qrts[2]-qrts[1]
  h <- 1.5 * iqr
  x[x<qrts[1]-h] <- caps[1]
  x[x>qrts[2]+h] <- caps[2]
  x
}

fitLMPW2 <- replace_outliers(fitLMPW$residuals)
par(mfrow = c(1,2))
```
```{r}
boxplot(fitLMPW2, main = "Sin datos atipicos",col=6)
hist(fitLMPW2)

```

Tras eliminar los datos atipicos se observa que tenemos una mejor distribucion de los datos, en donde la caja se encuentra centrada y ademas tenemos un histograma con una distribucion normal. \n

```{r}
plot(test$SalePrice, test$LotArea)
points(predL, test$LotArea, col="red",pch=15)

```

Como se observa en la grafica anterior podemos ver los puntos predichos, demostrando que tiene una buena prediccion.

### Efectividad y desempeño del modelo:

Realmente si hacemos un analisis desde el comienzo del modelo, podemos comprobar que el modelo tuvo una gran efectividad, si bien es cierto que tomamos variables muy especificas, el modelo tuvo no un desempeño perfecto, pero si algo notable y si vemos la grafica anterior: 

```{r visible=FALSE}
plot(test$SalePrice, test$LotArea)
points(predL, test$LotArea, col="red",pch=15)

```

Los puntos que se encuentran en rojo son todos los datos que logras precedir, y los puntos "normales" son los puntos reales, como podemos ver, son pocos los puntos que muestran una variacion muy amplia, en si podriamos decir que los puntos mas variados son puntos atipicos, pero, eso si, cabe destacar que toda la estimacion se hace en base a LotArea y si nos regresamos a la tabla siguiente: 


```{r include==FALSE }
pregunta2

```

Podemos observar que contamos con, como mayor distancia 100,000 en cada dato, por lo que, para ser una estimacion no esta absolutamente nada mal, si podemos mencionar algo, es que muy probablemente, si queremos una estimacion mucha mas aceptada, o por lo menos acortar la distancia entre datos, lo mas seguro es que lo lograriamos agregando muchas mas varibales (variables numericas) posiblemente podriamos tener un acierto mucho mayor, aunque tambien podria influir en que pueden haber muchos datos repetidos. Pero, siendo realistas, posiblemente si se pudieran realizar mas modelos, o crear desde cero una comparativa directa de cada metodo, seria una forma mucho mas facil y correcta de poder determinar los fallos, o bien tener un mejor acierto.

Si nos basamos en el coeficiente de correlacion de Spearman: 

```{r}
cor(data$SalePrice,data[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd","LotArea")], method = "spearman")
```

Como podemos ver, nuestro dato es de 0.708, que podemos obtener de eso, como bien sabemos el correlativo de Spearman mide la fuerza y la direccion nde la asociacion entre dos variables para determinar justamente la correlacion de ambas, en este caso nosotros decimos que la relacion entre el precio de la casa debe de ser correlativo a el LivArea, pero, para poder expresar mejor esta diferncia, veamos los siguientes ejemplos: 

1. Si utilizamos el año en la que fue construida: 

```{r}
cor(data$SalePrice,data$YearBuilt, method = "spearman")
```

Como podemos ver, esta correlacion esta muy justa y si lo vemos asi, esta peor que la relacion que tenemos seleccionada, asi mismo podemos intentar hacer la correlacion con otra variable, como por ejemplo: 


```{r}
cor(data$SalePrice,data$GarageArea, method = "spearman")
```

Como podemos ver, en este caso la correlacion es mayor, pero aun asi no supera la correlacion inicial. 

### Comparacion con el arbol de regresion:

Si recordamos el arbol de regresion de la hoja pasada: 
```{r include=FALSE}

library(rpart)
library(rpart.plot)
library(randomForest)


data<-read.csv('train.csv') 
df<-data[,c("LotFrontage","LotArea","GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","GarageYrBlt","GarageArea","YearRemodAdd", "SalePrice")]

m1<-rpart(SalePrice ~ ., data = df, method = "anova")

```
```{r include=TRUE}
rpart.plot(m1, type = 3, digits = 3, fallen.leaves = TRUE )

```

Si comparamos ambos metodos y tomando en cuenta el tiepo trabajado en ambas, se podria de decir que el metodo de regresion lineal es mucho mas rapido de hacer, pero quizas para tener mayor acierto o mejor efectividad es ligeramente mejor el arbol de regresion, ya que con el metodo de regresion lineal tuvimos un acierto del 0.7, mientras que en nuestro analisis de la hoja de trabajo anterior, obtuvimos un acierto de 0.8, tampoco es una diferencia muy abismal pero si es una mejora, por lo que si lo ponemos en terminos simples: 


  1. Cual es mejor para predecir: Arbol de regresion. 
  
  
  2. Cual se demoro mas en procesar: Regresion lineal.